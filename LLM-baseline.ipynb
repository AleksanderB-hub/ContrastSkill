{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad18654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai, json, logging\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import random\n",
    "from random import sample\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import evaluate\n",
    "seqeval = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58493940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data\n",
    "#Import the positive examples\n",
    "green = []\n",
    "with open('./Data/Supervised/Green/test.json', 'r') as f:\n",
    "    for line in f:\n",
    "        green.append(json.loads(line.strip()))\n",
    "say = []\n",
    "with open('./Data/Supervised/Sayfullina/test.json', 'r') as f:\n",
    "    for line in f:\n",
    "        say.append(json.loads(line.strip()))\n",
    "ss = []\n",
    "with open('./Data/Supervised/SkillSpan/test.json', 'r') as f:\n",
    "    for line in f:\n",
    "        ss.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d46667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples for GPT-4\n",
    "random.seed(2137)\n",
    "green_300= random.sample(green, 300)\n",
    "ss_300= random.sample(ss, 300)\n",
    "say_300= random.sample(say, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # Insert your OpenAI API key here\n",
    "    api_key=(\"\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989056c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_system = (\n",
    "    \"You are an information-extraction assistant.\\n\"\n",
    "    \"Task: given ONE tokenized job-advert sentence, output a BIO tag for \"\n",
    "    \"every token describing a skill or a competence. A tag must be exactly \\\"B\\\", \\\"I\\\", or \\\"O\\\".\\n\"\n",
    "    \"Return ONLY a JSON object of the form: \"\n",
    "    \"\\'{\\\"predicted_spans\\\": [\\\"B\\\", \\\"I\\\", \\\"O\\\", ...]}\\'.\\n\"\n",
    "    \"Do NOT add any other keys, comments, or text.\\n\"\n",
    "    \"Make sure the length of the \\\"predicted_spans\\\" matches the length of tokens.\\n\"\n",
    "    \"If the user supplies example tokens-tags pairs first, follow the provided pattern.\"\n",
    ")\n",
    "\n",
    "instruction_system_say = (\n",
    "    \"You are an information-extraction assistant.\\n\"\n",
    "    \"Task: given ONE tokenized job-advert sentence, output a BIO tag for \"\n",
    "    \"every token describing a SOFT skill or a competence. A tag must be exactly \\\"B\\\", \\\"I\\\", or \\\"O\\\".\\n\"\n",
    "    \"Return ONLY a JSON object of the form: \"\n",
    "    \"\\'{\\\"predicted_spans\\\": [\\\"B\\\", \\\"I\\\", \\\"O\\\", ...]}\\'.\\n\"\n",
    "    \"Do NOT add any other keys, comments, or text.\\n\"\n",
    "    \"Make sure the length of the \\\"predicted_spans\\\" matches the length of tokens.\\n\"\n",
    "    \"If the user supplies example tokens-tags pairs first, follow the provided pattern.\"\n",
    ")\n",
    "\n",
    "\n",
    "TOOLS = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"tagger\",\n",
    "        \"description\": \"Return BIO tags for a token list\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"predicted_spans\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\", \"enum\": [\"B\", \"I\", \"O\"]},\n",
    "                    \"description\": \"BIO tag per token\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"predicted_spans\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "FEW_SHOT_EXAMPLES_SS = [\n",
    "    {\"tokens\": [\"Webpack\", \"React\", \"&\", \"Redux\"], \"predicted_spans\": [\"B\", \"B\", \"O\", \"B\"]},\n",
    "    {\"tokens\": [\"You\", \"will\", \"have\", \"experience\", \"with\", \"application\", \"design\", \"&\", \"architecture\", \"using\", \"modern\", \"design\", \"patterns\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\", \"B\", \"I\", \"I\"]},\n",
    "    {\"tokens\": [\"Become\", \"a\", \"part\", \"of\", \"our\", \"team\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]},\n",
    "    {\"tokens\": [\"About\", \"<ORGANIZATION>\", \"<ORGANIZATION>\", \"<ORGANIZATION>\", \"<ORGANIZATION>\", \"is\", \"the\", \"hub\", \"for\", \"innovation\", \"at\", \"<ORGANIZATION>\", \"<ORGANIZATION>\", \"<ORGANIZATION>\", \"<ORGANIZATION>\", \"<ORGANIZATION>\", \"(\", \"<ORGANIZATION>\", \".\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]},\n",
    "    {\"tokens\": [\"<ORGANIZATION>\", \"is\", \"looking\", \"for\", \"a\", \"Senior\", \"Java\", \"Developer\", \"to\", \"build\", \"new\", \"features\", \"design\", \"and\", \"implement\", \"useful\", \"API\", \"methods\", \"and\", \"increase\", \"the\", \"reliability\", \"of\", \"our\", \"software\", \"continuously\", \".\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\"]}\n",
    "]\n",
    "\n",
    "FEW_SHOT_EXAMPLES_GREEN = [\n",
    "    {\"tokens\": [\"This\", \"UK\", \"based\", \"staff\", \"position\", \"is\", \"within\", \"the\", \"technical\", \"directorate\", \"team\", \"with\", \"the\", \"successful\", \"candidate\", \"gaining\", \"the\", \"responsibility\", \"for\", \"the\", \"operations\", \"of\", \"performance\", \"optimisation\", \"teams\", \"and\", \"shall\", \"have\", \"the\", \"opportunity\", \"to\", \"review\", \"and\", \"implement\", \"improvements\", \"to\", \"operational\", \"practise\", \".\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\"]},\n",
    "    {\"tokens\": [\"Rare\", \"opening\", \"for\", \"a\", \"highcalibre\", \"assistant\", \"at\", \"this\", \"prestigious\", \"City\", \"firm\", \"with\", \"a\", \"highly\", \"regarded\", \"commercial\", \"property\", \"department\", \".\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]},\n",
    "    {\"tokens\": [\"topologies\", \"as\", \"well\", \"as\", \"surface\", \"mount\", \"assembly\", \"is\", \"essential\", \".\"], \"predicted_spans\": [\"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\"]},\n",
    "    {\"tokens\": [\"Responsibilities\", \"will\", \"be\", \"an\", \"interesting\", \"split\", \"of\", \"3rd\", \"/\", \"4th\", \"line\", \"support\", \"to\", \"project\", \"work\", \"\\\"\", \"giving\", \"the\", \"incumbent\", \"some\", \"fantastic\", \"exposure\", \"to\", \"design\", \"and\", \"planning\", \"of\", \"infrastructure\", \"projects\", \".\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"O\", \"B\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\"]},\n",
    "    {\"tokens\": [\"You\", \"may\", \"also\", \"be\", \"involved\", \"in\", \"Method\", \"Development\", \"and\", \"Validation\", \".\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\"]}\n",
    "]\n",
    "\n",
    "FEW_SHOT_EXAMPLES_SAY = [\n",
    "    {\"tokens\": [\"ability\", \"to\", \"work\", \"under\", \"stress\", \"condition\"], \"predicted_spans\": [\"O\", \"O\", \"B\", \"I\", \"I\", \"O\"]},\n",
    "    {\"tokens\": [\"workplace\", \"excellent\", \"interpersonal\", \"and\", \"communication\", \"skill\", \"diplomatic\", \"and\", \"negotiation\", \"skill\", \"the\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"O\", \"O\", \"O\", \"O\"]},\n",
    "    {\"tokens\": [\"confidence\", \"in\", \"decision\", \"making\", \"abilities\", \"and\", \"deal\", \"effectively\", \"with\", \"unexpected\"], \"predicted_spans\": [\"O\", \"O\", \"B\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\"]},\n",
    "    {\"tokens\": [\",\", \"linux\", \"javascript\", \"ajax\", \"html\", \"xml\", \"cs\", \"experience\", \"with\", \"dynamic\", \"databasedriven\", \"website\", \"it\", \"relate\", \"degree\", \"this\", \"position\", \"offer\", \"you\", \"the\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]},\n",
    "    {\"tokens\": [\"excellent\", \"communicator\", \"and\", \"a\", \"hard\", \"worker\"], \"predicted_spans\": [\"O\", \"O\", \"O\", \"O\", \"B\", \"I\"]}    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c648b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_prompt(test_tokens, few_shot_examples):\n",
    "    msg = []\n",
    "    msg.append(f\"The examples below show perfectly assigned BIO tags:\\n\")\n",
    "    for ex in few_shot_examples:\n",
    "        msg.append(f\"Tokens: {ex['tokens']}\\n\"\n",
    "                   f\"Output: {{\\\"predicted_spans\\\": {ex['predicted_spans']}}}\\n\"\n",
    "        )\n",
    "    msg.append(f\"Following the same pattern assign BIO tags for the following {len(test_tokens)} tokens:\\n\")\n",
    "    msg.append(f\"Tokens: {test_tokens}\\nOutput: \")\n",
    "    return \"\".join(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b1b3f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_3 = \"gpt-3.5-turbo\"\n",
    "model_type_4 = \"gpt-4.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daddc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instruction-tuned\n",
    "def generate_sentences_with_word(dictionary, few_shot=False, few_shot_examples_data=None, type=None):\n",
    "\n",
    "    output_list, failed_cases, bad = [], [], 0\n",
    "    bar = tqdm(dictionary, desc=\"LLM tagging\", unit=\"sent\")\n",
    "    \n",
    "    if type == 'say':\n",
    "        instruction_to_use = instruction_system_say\n",
    "    else:\n",
    "        instruction_to_use = instruction_system   \n",
    "    for item in bar:\n",
    "        tokens = item['tokens']\n",
    "        gold_tags = item['tags_skill']\n",
    "        \n",
    "        #build user prompt \n",
    "        user_prompt = build_user_prompt(tokens, few_shot_examples_data) if few_shot else (\n",
    "        f\"Assign BIO tags for the following {len(tokens)} tokens:\\nTokens: {tokens}\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_type_3,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": instruction_to_use},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                tools = TOOLS,\n",
    "                tool_choice={\"type\": \"function\", \"function\": {\"name\": \"tagger\"}},\n",
    "                max_tokens=len(tokens) + 50,\n",
    "                temperature=0.0,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "        \n",
    "            tags = response.choices[0].message.tool_calls[0].function.arguments\n",
    "            predicted = json.loads(tags)[\"predicted_spans\"]\n",
    "            if len(predicted) != len(tokens):\n",
    "                raise ValueError(\"length mismatch\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"LLM error: {e}\")\n",
    "            predicted = ['O'] * len(tokens)\n",
    "            failed_cases.append(tokens) \n",
    "            bad += 1\n",
    "        \n",
    "        bar.set_postfix(bad=bad)  \n",
    "        output_list.append({\"tokens\": tokens,\n",
    "                        \"predicted_tags\": predicted,\n",
    "                        \"gold_tags\": gold_tags})\n",
    "    bar.close()\n",
    "    print(f\"There were {bad} errors due to the length mismatch\")\n",
    "    \n",
    "    return output_list, failed_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c125edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green zero-shot (GPT-3.5-turbo)\n",
    "green_llm, failed_g_zero = generate_sentences_with_word(green, few_shot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bae8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green zero-shot (GPT-4.1)\n",
    "green_llm_4, failed = generate_sentences_with_word(green_300, few_shot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e60eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skillspan zero-shot (GPT-3.5-turbo)\n",
    "ss_llm, failed_ss = generate_sentences_with_word(ss, few_shot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skillspan zero-shot (GPT-4.1)\n",
    "ss_llm_4, failed_ss_4 = generate_sentences_with_word(ss_300, few_shot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ea130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sayfullina zero-shot (GPT-3.5-turbo)\n",
    "say_llm_zero, failed_say_zero = generate_sentences_with_word(say, few_shot=False, type='say')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sayfullina zero-shot (GPT-4.1)\n",
    "say_llm_4, failed_say_4 = generate_sentences_with_word(say_300, few_shot=False, type='say')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb017e24",
   "metadata": {},
   "source": [
    "## Few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbfe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green few-shot (GPT-3.5-turbo)\n",
    "green_llm_few, failed_g_few = generate_sentences_with_word(green, few_shot=True, few_shot_examples_data=FEW_SHOT_EXAMPLES_GREEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skillspan few-shot (GPT-3.5-turbo)\n",
    "ss_llm_few, failed_ss_few = generate_sentences_with_word(ss, few_shot=True, few_shot_examples_data=FEW_SHOT_EXAMPLES_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sayfullina few-shot (GPT-3.5-turbo)\n",
    "say_llm_few, failed_say_few = generate_sentences_with_word(say, few_shot=True, few_shot_examples_data=FEW_SHOT_EXAMPLES_SAY, type='say')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e20182e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data):\n",
    "    predictions = [x['predicted_tags'] for x in data]\n",
    "    true_labels = [x['gold_tags'] for x in data]\n",
    "    results = seqeval.compute(predictions=predictions, references=true_labels)\n",
    "    \n",
    "    overall_precision = results['overall_precision'] \n",
    "    overall_recall = results['overall_recall']\n",
    "    overall_f1 = results['overall_f1']\n",
    "    \n",
    "    print(f'F1-span score is {round(overall_f1*100, 2)}%, with {round(overall_precision*100, 2)}% precision and {round(overall_recall*100, 2)}% recall.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
