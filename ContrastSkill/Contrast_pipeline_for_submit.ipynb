{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic libraries\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import logging \n",
    "import copy \n",
    "import sys\n",
    "import shutil  \n",
    "import faiss\n",
    "import torch\n",
    "\n",
    "\n",
    "#For controlling the loss functions etc. \n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "#Samplers\n",
    "from torch.utils.data import (DataLoader, RandomSampler, DistributedSampler)\n",
    "#Importing the distributed module\n",
    "import torch.distributed as dist\n",
    "#Optimizer\n",
    "from torch.optim import AdamW \n",
    "#from transformers import AdamW\n",
    "#Getting the linear sechdule with warmup\n",
    "from transformers import get_linear_schedule_with_warmup as WarmupLinearScheduler\n",
    "#TQDM\n",
    "from tqdm import tqdm, trange\n",
    "#For torch modules\n",
    "import torch.nn\n",
    "#For torch functional\n",
    "import torch.nn.functional as F\n",
    "#for models \n",
    "from transformers import (BertConfig, BertModel, BertTokenizerFast, RobertaConfig, RobertaModel, RobertaTokenizerFast)\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification\n",
    "#For testing to wokr on a sample fo data\n",
    "from torch.utils.data import Subset\n",
    "#For distributer training\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "#For supervised evaluation \n",
    "import evaluate \n",
    "seqeval = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrast_functions_1 import NT_xent, normalize_embeddings, Contrastskill, skill_dataloader, vectorizer_sentence, BioTaggingModel, tensorize_data, predict, check_pred, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Classes = {\n",
    "    'jobbert': (AutoConfig, AutoModel, AutoTokenizer),\n",
    "    'bert': (BertConfig, BertModel, BertTokenizerFast),\n",
    "    'roberta': (AutoConfig, AutoModel, AutoTokenizer),#(RobertaConfig, RobertaModel, RobertaTokenizerFast),\n",
    "    'joberta': (AutoConfig, AutoModel, AutoTokenizer)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Training and evaluation configuration\")\n",
    "\n",
    "    #General settings\n",
    "    parser.add_argument('--local_rank', type=int, default=-1, help='Rank for distributed training')\n",
    "    parser.add_argument('--available_gpus', type=int, default=1, help='Number of GPUs to use')\n",
    "    parser.add_argument('--device', type=str, default='cuda', help='Device to use for training')\n",
    "    parser.add_argument('--seed', type=int, default=21, help='Random seed for reproducibility')\n",
    "\n",
    "    #Model settings\n",
    "    parser.add_argument('--model_type', type=str, default='joberta', help='Model type')\n",
    "    parser.add_argument('--model_version', type=str, default='jjzha/jobberta-base', help='Model version')\n",
    "    parser.add_argument('--reference_epochs', type=int, default = 20, help='This is the reference training epochs number used for learning rate scheduling. It applies to the fine-tuning stage and works independently of supervised_epochs')\n",
    "\n",
    "    #Training settings for Contrastive Pre-Training Stage\n",
    "    parser.add_argument('--contrastive_train', action='store_true', help='Enable contrastive training')\n",
    "    parser.add_argument('--lowercase', action='store_true', help='Convert text to lowercase (for uncased models)')\n",
    "    parser.add_argument('--weight_relevant', type=float, default=1.0, help='Weight for relevant tokens')\n",
    "    parser.add_argument('--training_size', type=int, default=0, help='Training size for the contrastive stage')\n",
    "    parser.add_argument('--prepare_data', action='store_true', help='Prepare the Pre-training dataset (alternatively you can set it to false and provide your own data, assuming it follows the same structure)')\n",
    "    parser.add_argument('--epochs', type=int, default=3, help='Number of training epochs for the contrastive pre-training')\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='Batch size')\n",
    "    parser.add_argument('--early_stopping_steps', type=int, default=-1, help='Exact number of training steps to be used')\n",
    "    parser.add_argument('--learning_rate', type=float, default=5e-5, help='Learning rate')\n",
    "    parser.add_argument('--epsilon_adam', type=float, default=1e-8, help='Epsilon value for the optimizer')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0, help='Weight decay')\n",
    "    parser.add_argument('--warmup_prop', type=float, default=0.1, help='Proportion of the pre-training data to be used for the warmup')\n",
    "    parser.add_argument('--accumulate_gradients', type=int, default=1, help='In case of insufficient memory gradients can be accumulated to simulate greater batch size (significantly extends the computation)')\n",
    "    parser.add_argument('--gradient_threshold', type=float, default=1.0, help='A maximum threshold for gradients')\n",
    "    parser.add_argument('--writer_update_steps', type=int, default=10, help='A number of steps at which the current loss, gradients and learning rate will be recorded to the scheduler')\n",
    "    parser.add_argument('--dropout', type=float, default=0.1, help='A dropout proportion for the pre-training')\n",
    "    parser.add_argument('--output_size', type=int, default=768, help='Size of the embedding layer')\n",
    "    parser.add_argument('--limit', type=int, default=128, help='The upper bound for the sequence length, all other sequences will be padded to this value.')\n",
    "    parser.add_argument('--mode', type=int, default=1, help='The training mode for the framework. 0-only pre-trains the contrastive model, 1-pre-trains the contrastive model and fine-tunes on a downstream task, 2-only fine-tunes on a downstream task (only predicts if supervised_train is set to True)')\n",
    "    #Negative Sampling\n",
    "    parser.add_argument('--strong_negatives', action='store_true', help='Determine whether strong negative sampling is to be used (does not work with \"flip\" negatives)')\n",
    "    parser.add_argument('--negative_type', type=str, default='base', help='Determine the negative sampling strategy (base or flip)')\n",
    "    parser.add_argument('--number_negative_pairs', type=int, default=2, help='Number of negative pairs (works only with base negative pairing type)')\n",
    "    parser.add_argument('--strong_negative_prob', type=float, default=1.0, help='The probability of strong negative pair if strong__negatives is set to True')\n",
    "    #Loss\n",
    "    parser.add_argument('--temperature', type=float, default=0.1, help='Temperature for the InfoNCE loss')\n",
    "    parser.add_argument('--main_loss_weight', type=float, default=1.0, help='The weight for the InfoNCE loss (leave at default)')\n",
    "    \n",
    "    #Training Settings for the Fine-Tuning Stage\n",
    "    parser.add_argument('--supervised_dataset', type=str, default='SkillSpan', help='Determine which dataset you want to use [SkillSpan, Green, Sayfullina]')\n",
    "    parser.add_argument('--tagging_type', type=str, default='bio', help='Sets a tagging type, default is BIO. If a different data structure were to be explored the adequate adjustments must be made to the backend.py file')\n",
    "    parser.add_argument('--supervised_train', action='store_true', help='Determine whether to fine-tune the model on a downstream task')\n",
    "    parser.add_argument('--supervised_raw', action='store_true', help='Determine whether to use a base model (True) or contrastive pre-trained version (False)')\n",
    "    parser.add_argument('--supervised_num_labels', type=int, default=3, help='Number of labels for a downstream task. Similarly as tagging_type if other data is used, the backend must be adjusted.')\n",
    "    parser.add_argument('--supervised_epochs', type=int, default=20, help='The number of epochs to be used in a supervised setting')\n",
    "    parser.add_argument('--supervised_early_stopping_steps', type=int, default=-1, help='The exact number of training steps to trigger early stopping')\n",
    "    parser.add_argument('--supervised_batch_size', type=int, default=16, help='Batch size for the fine-tuned model')\n",
    "    parser.add_argument('--supervised_learning_rate', type=float, default=5e-5, help='Learning Rate for the fine-tuned model')\n",
    "    parser.add_argument('--supervised_weight_decay', type=float, default=0.0, help='Weight decay')\n",
    "    parser.add_argument('--supervised_warmup_prop', type=float, default=0.0, help='Warmup proportion for fine-tuning')\n",
    "    parser.add_argument('--supervised_accumulate_gradients', type=int, default=0.0, help='Determine whether to simulate larger batch size and accumulate gradients')\n",
    "    parser.add_argument('--dropout_sup', type=float, default=0.0, help='Dropout proportion for fine-tuned model')\n",
    "    parser.add_argument('--patience', type=int, default=5, help='Patience, used for determining the optimal number of epochs for the fine-tuned model')\n",
    "    parser.add_argument('--predict', action='store_true', help='If set, the fine-tuned model will be used to predict the test dataset')\n",
    "    \n",
    "    #Paths\n",
    "    parser.add_argument('--data_directory', type=str, default='/path/to/data', help='Path to data directory, specify your path where all downstream task datasets are stored')\n",
    "    parser.add_argument('--model_directory', type=str, default='/path/to/models', help='Path to where your models are stored')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    \"\"\"Function to configure random seed for all sub-processes.\"\"\"\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.available_gpus > 1:\n",
    "        torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributed_learning(args):\n",
    "    \"\"\"\n",
    "    Function to configure training environment. \n",
    "    This ensures that if more than 1 GPUS are available, they will be utilised\n",
    "    \"\"\"\n",
    "    if args.available_gpus > 1:\n",
    "        args.local_rank = 0\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        args.device = torch.device('cuda', args.local_rank)\n",
    "        dist.init_process_group(backend= 'nccl')\n",
    "    else:\n",
    "        args.local_rank = -1\n",
    "        args.device = torch.device(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_contrast(args, model, training_data):\n",
    "    \"\"\"\n",
    "    This is the train function for the contrastive learning stage. It calls all of the classes defined earlier.\n",
    "    It structures the training process and ensures efficient processing of data and batches. \n",
    "    In addition it also configures a summary writer so that some learning process characteristics can be investigated.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Configure a SummaryWriter\n",
    "    summary_writer = SummaryWriter(log_dir = (args.model_directory + '/Unsupervised/Logs'))\n",
    "\n",
    "    #Define dataloaders and samplers\n",
    "    #Determine the training batch size based on the number of GPUs\n",
    "    batch_size = args.batch_size * max(1, args.available_gpus)\n",
    "\n",
    "    #Sampler\n",
    "    if args.local_rank == 0:\n",
    "        train_sampler = DistributedSampler(training_data)\n",
    "    else:\n",
    "        train_sampler = RandomSampler(training_data)\n",
    "\n",
    "    #Dataloader\n",
    "    dataloader_training = DataLoader(training_data, sampler= train_sampler, batch_size= batch_size)\n",
    "\n",
    "    #Determine the training parameters (epochs, weight_decay, optimizer, scheduler, gradient accumulation)\n",
    "\n",
    "    #Account for early stopping\n",
    "    #Adjust the number of gradient updates if gradient accumulation is used\n",
    "    num_weight_updates = len(dataloader_training) // args.accumulate_gradients\n",
    "    if args.early_stopping_steps > 0:\n",
    "        #Determine the number of epochs \n",
    "        args.epochs = args.early_stopping_steps // num_weight_updates + 1\n",
    "        training_steps = args.early_stopping_steps\n",
    "    else:\n",
    "        training_steps = num_weight_updates * args.epochs\n",
    "\n",
    "    #Determine optimizer and scheduler \n",
    "    #Since we want to apply weight decay we need to make sure that the the embedding, normalization and bias layers are not affected\n",
    "\n",
    "    no_weight_decay_layers = ['bias', 'LayerNorm.weight', 'embedding', 'BatchNorm.weight', 'InstanceNorm.weight', 'GroupNorm.weight']\n",
    "    no_decay_params = []\n",
    "    decay_params = []\n",
    "    for name, params in model.named_parameters():\n",
    "        if any(key in name for key in no_weight_decay_layers):\n",
    "            no_decay_params.append(params)\n",
    "        else:\n",
    "            decay_params.append(params)\n",
    "\n",
    "    adjusted_parameters = [\n",
    "        {'params': no_decay_params, 'weight_decay': 0.0},\n",
    "        {'params': decay_params, 'weight_decay': args.weight_decay}\n",
    "    ]\n",
    "        \n",
    "    #Define optimizer \n",
    "    optimizer = AdamW(params= adjusted_parameters, lr= args.learning_rate, eps= args.epsilon_adam)\n",
    "\n",
    "    #Scheduler \n",
    "    scheduler = WarmupLinearScheduler(optimizer, num_warmup_steps= math.floor(args.warmup_prop * training_steps), num_training_steps= training_steps)\n",
    "    \n",
    "    #Training \n",
    "    #initialize parameters\n",
    "    iterations = 0\n",
    "    total_loss, previous_loss = 0.0, 0.0\n",
    "    total_magnitude_accumulated, gradient_count = 0, 0\n",
    "\n",
    "    #Update logger\n",
    "    logger.info('Begin Training...')\n",
    "    logger.info('Training Sample Size = %d', len(training_data))\n",
    "    logger.info('Total Training Steps = %d', training_steps)\n",
    "    logger.info('Epochs = %d', args.epochs)\n",
    "    logger.info('Effective batch_size = %d', (args.batch_size * args.accumulate_gradients * args.available_gpus))\n",
    "\n",
    "    #Set gradients to 0\n",
    "    model.zero_grad()\n",
    "\n",
    "    #Begin by iterating through entire training sample\n",
    "    total_iterator = trange(int(args.epochs), desc='Iterating through epochs...')\n",
    "    for _ in total_iterator:\n",
    "        epoch_iterator = tqdm(dataloader_training, total=len(dataloader_training), desc='Iterating through batches within epoch...', mininterval= 10, miniters= 1, ncols= 100)\n",
    "\n",
    "        #Iterate through epochs\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            epoch_iterator.update()\n",
    "            epoch_iterator.refresh()\n",
    "            #Transfer each batch into the designated device\n",
    "            batch = tuple(example.to(args.device) for example in batch)\n",
    "            \n",
    "            #Define inputs': batch[1],\n",
    "            inputs = {'anchor_ids': batch[0],\n",
    "                      'anchor_input_masks': batch[1],          \n",
    "                      'anchor_output_masks': batch[2],\n",
    "                      'anchor_special_masks': batch[3],\n",
    "                      'pairs_ids': batch[4],\n",
    "                      'pairs_input_masks': batch[5],\n",
    "                      'pairs_output_masks': batch[6],\n",
    "                      'pairs_special_masks': batch[7],\n",
    "                      'labels': batch[8]\n",
    "                      }\n",
    "            # print(inputs)\n",
    "\n",
    "            #Calculate loss\n",
    "            loss = model(**inputs)\n",
    "\n",
    "            #Adjust the batch loss with the distributed training or gradient accumulation\n",
    "            if args.accumulate_gradients > 1:\n",
    "                loss = loss / args.accumulate_gradients\n",
    "\n",
    "            if args.available_gpus > 1 and args.local_rank != -1:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            #Clip Gradients to address exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = args.gradient_threshold)\n",
    "\n",
    "            #Combine the total epoch loss (accumulate batch losses)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            #Since gradient accumulation can be performed we need to ensure that the optimizer and scheduler are updated once accumulation is finished\n",
    "            if (step + 1) % args.accumulate_gradients == 0:\n",
    "\n",
    "            #Initialize the in-batch gradient parameter (to store in-batch magnitudes)\n",
    "                batch_magnitude = 0\n",
    "\n",
    "            #Store the gradients before resetting them (for all parameters)\n",
    "                for _, param in model.named_parameters():\n",
    "                    if param.grad is not None: \n",
    "                        #Get the euclidean (gradient magnitude for each parm)\n",
    "                        magnitude = param.grad.data.norm(2)\n",
    "                        #Raise each magnitude to the power of 2\n",
    "                        magnitude = magnitude ** 2\n",
    "                        #Sum all the normalized gradients\n",
    "                        batch_magnitude += magnitude\n",
    "\n",
    "                #Get the overall magnitude (i.e., gradient norm for the entire batch)\n",
    "                total_magnitude = batch_magnitude ** 0.5\n",
    "                total_magnitude_accumulated += total_magnitude\n",
    "                gradient_count += 1\n",
    "\n",
    "                #Update the optimizer and scheduler         \n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                #Once the batch (or accumulated batch) is processed reset the gradients\n",
    "                model.zero_grad()\n",
    "                iterations += 1\n",
    "\n",
    "                #Update the writer with gradients, learning rate and loss\n",
    "                if iterations % args.writer_update_steps == 0:\n",
    "                    average_gradient_norm = total_magnitude_accumulated / gradient_count\n",
    "                    avg_loss_per_writer_update = (total_loss - previous_loss) / args.writer_update_steps\n",
    "                    summary_writer.add_scalar(tag= 'gradient norms', scalar_value= average_gradient_norm, global_step= iterations)\n",
    "                    summary_writer.add_scalar(tag= 'learning rate', scalar_value= scheduler.get_last_lr()[0], global_step= iterations)\n",
    "                    summary_writer.add_scalar(tag= 'loss', scalar_value= avg_loss_per_writer_update, global_step= iterations)\n",
    "                    previous_loss = total_loss\n",
    "\n",
    "                    #Reset the gradients norm after each writer update\n",
    "                    gradient_count = 0\n",
    "                    total_magnitude_accumulated = 0  \n",
    "\n",
    "        #Apply early stopping \n",
    "            if iterations >= args.early_stopping_steps and args.early_stopping_steps > 0:\n",
    "                epoch_iterator.close() \n",
    "                total_iterator.close()\n",
    "                break\n",
    "\n",
    "        if iterations >= args.early_stopping_steps and args.early_stopping_steps > 0:\n",
    "            break \n",
    "\n",
    "    summary_writer.close()\n",
    "\n",
    "    #Save the model and training arguments \n",
    "    torch.save(args, os.path.join(args.model_directory, 'model_contrastive_training_args.bin'))\n",
    "    if args.available_gpus > 1 and args.local_rank != -1:\n",
    "        torch.save(model.module.state_dict(), os.path.join(args.model_directory, 'model_contrastive_stage.bin'))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), os.path.join(args.model_directory, 'model_contrastive_stage.bin'))\n",
    "\n",
    "    logger.info(f\"Model was successfully trained and saved to the {args.model_directory}.\")\n",
    "\n",
    "    return print(f'Stage 1 pre-training finished overall loss is: {total_loss / iterations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised(args, supervised_training_data, model, tokenizer=None, dev_data=None):\n",
    "    \"\"\"\n",
    "    This function is used to perform a supervised training.\n",
    "    The training is can be initialized with the contrastive\n",
    "    pre-trained model from the stage_1. \n",
    "    Since the supervised model is simply fine-tuned transformer,\n",
    "    the final model will always be a version of the initial model. \n",
    "    E.g., If the contrastive stage used BERT, supervised learning stage will utilise pre-trained BERT. \n",
    "    \"\"\"\n",
    "    #Configure a Logger and Summary writer \n",
    "    summary_writer = SummaryWriter(log_dir = (args.model_directory + '/Supervised/Logs'))\n",
    "\n",
    "    #Define dataloaders and samplers\n",
    "    #Determine the training batch size based on the number of GPUs\n",
    "    batch_size = args.supervised_batch_size * max(1, args.available_gpus)\n",
    "\n",
    "    #Sampler\n",
    "    if args.local_rank == 0:\n",
    "        train_sampler = DistributedSampler(supervised_training_data)\n",
    "    else:\n",
    "        train_sampler = RandomSampler(supervised_training_data)\n",
    "\n",
    "    data_loader_supervised = DataLoader(supervised_training_data, sampler= train_sampler, batch_size= batch_size)\n",
    "    \n",
    "    #Account for early stopping and gradient accumulation \n",
    "    #Adjust the number of gradient updates if gradient accumulation is used\n",
    "    num_weight_updates = len(data_loader_supervised) // args.supervised_accumulate_gradients\n",
    "    if args.supervised_early_stopping_steps > 0:\n",
    "        #Determine the number of epochs \n",
    "        args.supervised_epochs = args.supervised_early_stopping_steps // num_weight_updates + 1\n",
    "        training_steps = args.supervised_early_stopping_steps\n",
    "    else:\n",
    "        training_steps = num_weight_updates * args.reference_epochs\n",
    "    \n",
    "    #Weight Decay\n",
    "    no_weight_decay_layers = ['bias', 'LayerNorm.weight', 'embedding', 'BatchNorm.weight', 'InstanceNorm.weight', 'GroupNorm.weight']\n",
    "    no_decay_params = []\n",
    "    decay_params = []\n",
    "    for name, params in model.named_parameters():\n",
    "        if any(key in name for key in no_weight_decay_layers):\n",
    "            no_decay_params.append(params)\n",
    "        else:\n",
    "            decay_params.append(params)\n",
    "\n",
    "    adjusted_parameters = [\n",
    "        {'params': no_decay_params, 'weight_decay': 0.0},\n",
    "        {'params': decay_params, 'weight_decay': args.weight_decay}\n",
    "    ]\n",
    "    \n",
    "    optimizer = AdamW(adjusted_parameters, eps= args.epsilon_adam, lr= args.supervised_learning_rate)\n",
    "    scheduler = WarmupLinearScheduler(optimizer=optimizer, num_warmup_steps= math.floor(training_steps * args.supervised_warmup_prop), num_training_steps= training_steps) \n",
    "    \n",
    "    #Begin training \n",
    "    #initialize parameters\n",
    "    iterations = 0\n",
    "    total_loss, previous_loss = 0.0, 0.0\n",
    "    total_magnitude_accumulated, gradient_count = 0, 0\n",
    "    previous_best_f1, patience = 0, 0\n",
    "\n",
    "    #Update logger\n",
    "    logger.info('Begin Training...')\n",
    "    logger.info('Training Sample Size = %d', len(supervised_training_data))\n",
    "    logger.info('Total Training Steps (scheduler) = %d', training_steps)\n",
    "    logger.info('Reference Epochs (scheduler) = %d', args.reference_epochs)\n",
    "    logger.info('Actual Training Epochs = %d', args.supervised_epochs)\n",
    "    logger.info('Effective batch_size = %d', args.supervised_batch_size * args.supervised_accumulate_gradients * (args.available_gpus))\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    total_iterator = trange(int(args.supervised_epochs), desc= 'Iterating through epochs...')\n",
    "    for epoch in total_iterator:\n",
    "        epoch_iterator = tqdm(data_loader_supervised, total=len(data_loader_supervised), desc='Iterating through batches within epoch...', mininterval= 10, miniters= 1, ncols= 100)\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            epoch_iterator.update()\n",
    "            epoch_iterator.refresh()\n",
    "            batch = tuple(example.to(args.device) for example in batch)\n",
    "            inputs = {\n",
    "                'inputs_ids': batch[0],\n",
    "                'inputs_mask': batch[1],\n",
    "                'labels_mask': batch[2]\n",
    "            }\n",
    "            \n",
    "            loss = model(**inputs)\n",
    "            \n",
    "            #Adjust for the gradient accumulation and distributed environments\n",
    "            if args.supervised_accumulate_gradients > 1:\n",
    "                loss = loss / args.supervised_accumulate_gradients\n",
    "                \n",
    "            if args.available_gpus > 1 and args.local_rank != -1:\n",
    "                loss = loss.mean()\n",
    "                \n",
    "            loss.backward()\n",
    "            \n",
    "            #Clip Gradients to address exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = args.gradient_threshold)\n",
    "            \n",
    "            #Accumulate the total loss so far\n",
    "            total_loss += loss.item()\n",
    "            if (step + 1) % args.supervised_accumulate_gradients == 0:\n",
    "                \n",
    "                #Initialize the in-batch gradient parameter (to store in-batch magnitudes)\n",
    "                batch_magnitude = 0\n",
    "\n",
    "                #Store the gradients before resetting them (for all parameters)\n",
    "                for _, param in model.named_parameters():\n",
    "                    if param.grad is not None: \n",
    "                        #Get the euclidean (gradient magnitude for each parm)\n",
    "                        magnitude = param.grad.data.norm(2)\n",
    "                        #Raise each magnitude to the power of 2\n",
    "                        magnitude = magnitude ** 2\n",
    "                        #Sum all the normalized gradients\n",
    "                        batch_magnitude += magnitude\n",
    "\n",
    "                #Get the overall magnitude (i.e., gradient norm for the entire batch)\n",
    "                total_magnitude = batch_magnitude ** 0.5\n",
    "                total_magnitude_accumulated += total_magnitude\n",
    "                gradient_count += 1\n",
    "                \n",
    "            #update the optimizer and scheduler\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            #Reset the gradients\n",
    "            model.zero_grad()\n",
    "            iterations += 1\n",
    "            \n",
    "            #Update to a Summary Writer\n",
    "            \n",
    "            if iterations % args.writer_update_steps == 0:\n",
    "                gradient_norm = total_magnitude_accumulated / gradient_count\n",
    "                avg_loss_per_update = (total_loss - previous_loss) / args.writer_update_steps\n",
    "                summary_writer.add_scalar(tag= 'gradient_norm', scalar_value= gradient_norm, global_step= iterations)\n",
    "                summary_writer.add_scalar(tag= 'learning_rate', scalar_value= scheduler.get_last_lr()[0], global_step= iterations)\n",
    "                summary_writer.add_scalar(tag= 'loss', scalar_value= avg_loss_per_update, global_step= iterations)\n",
    "                previous_loss = total_loss \n",
    "                \n",
    "            if iterations >= args.supervised_early_stopping_steps and (args.supervised_early_stopping_steps > 0 or patience >= args.patience):\n",
    "                #scheduler.close()\n",
    "                break\n",
    "        if dev_data:\n",
    "\n",
    "            print('Making prediction for current epoch...')\n",
    "            f1_step, precision_step, recall_step = evaluation(args, dev_data, model, tokenizer, final=False)\n",
    "\n",
    "            if f1_step > previous_best_f1:\n",
    "                print(f'The F1 score improved in epoch {epoch + 1}. New F1: {f1_step}, Precision: {precision_step} and Recall: {recall_step}, Previous best F1: {previous_best_f1}')\n",
    "                patience = 0 \n",
    "                previous_best_f1 = f1_step\n",
    "\n",
    "\n",
    "                #Delete the previous model (if it exists)\n",
    "                if os.path.exists(os.path.join(args.model_directory, 'model_supervised_stage.bin')):\n",
    "                    os.remove(os.path.join(args.model_directory, 'model_supervised_stage.bin'))\n",
    "                if os.path.exists(os.path.join(args.model_directory, 'model_supervised_training_args.bin')):\n",
    "                    os.remove(os.path.join(args.model_directory, 'model_supervised_training_args.bin'))\n",
    "\n",
    "                #Save the model \n",
    "                torch.save(args, os.path.join(args.model_directory, 'model_supervised_training_args.bin'))\n",
    "                if args.available_gpus > 1 and args.local_rank != -1:\n",
    "                    torch.save(model.module.state_dict(), os.path.join(args.model_directory, 'model_supervised_stage.bin'))\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), os.path.join(args.model_directory, 'model_supervised_stage.bin'))\n",
    "            else:\n",
    "                print(f'F1 score did not improve in epoch {epoch + 1}. Current F1: {f1_step}, Precision: {precision_step} and Recall: {recall_step}, Best F1: {previous_best_f1}')\n",
    "                patience += 1\n",
    "                \n",
    "        if iterations >= args.supervised_early_stopping_steps and (args.supervised_early_stopping_steps > 0 or patience >= args.patience):\n",
    "            print(f'The F1 score has not improved over consecutive {patience} runs, or the early steps defined was reached')\n",
    "            #scheduler.close()\n",
    "            break\n",
    "        \n",
    "    summary_writer.close()\n",
    "    \n",
    "    #Saving the final model \n",
    "    if dev_data is None:\n",
    "        torch.save(args, os.path.join(args.model_directory, 'model_supervised_training_args.bin'))\n",
    "        if args.available_gpus > 1 and args.local_rank != -1:\n",
    "            torch.save(model.module.state_dict(), os.path.join(args.model_directory, 'model_supervised_stage.bin'))\n",
    "        else:\n",
    "            torch.save(model.state_dict(), os.path.join(args.model_directory, 'model_supervised_stage.bin'))\n",
    "        \n",
    "\n",
    "    logger.info(f\"Model was successfully trained and saved to the {args.model_directory}.\")\n",
    "\n",
    "    return print(f'Stage 2 fine-tunning finished overall loss is: {total_loss / iterations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deploy(args):\n",
    "    \"This function is used to deploy the entire model architecture\"\n",
    "\n",
    "    if args.mode == 0 and not args.predict:\n",
    "        if os.path.exists(os.path.join(args.model_directory, 'model_contrastive_stage.bin')):\n",
    "            response = input(f\"Contrastive Stage Pre-training: Output directory ({os.path.join(args.model_directory, 'model_contrastive_stage.bin')}) already exists and is not empty. Do you want to overwrite? (Y/N): \")\n",
    "            if response.lower() in ['yes', 'y']:\n",
    "                print('Only the Stage_1 (Contrastive pre-training) will be performed')\n",
    "            else:\n",
    "                print('Model already pre-trained.')\n",
    "                sys.exit()\n",
    "\n",
    "    elif args.mode == 1 and not args.predict:\n",
    "        if os.path.exists(os.path.join(args.model_directory, 'model_supervised_stage.bin')) and os.path.exists(os.path.join(args.model_directory, 'model_contrastive_stage.bin')):\n",
    "            response = input(f\"Output directory for pre-trained model: ({os.path.join(args.model_directory, 'model_contrastive_stage.bin')}) and fine-tuned model ({os.path.join(args.model_directory, 'model_supervised_stage.bin')}) already exists and is not empty. Do you want to overwrite? (Y/N): \")\n",
    "            if response.lower() in ['yes', 'y']:\n",
    "                print('Both Stages of the pipeline will be trained')\n",
    "            else:\n",
    "                print('Both models are ready.')\n",
    "                sys.exit()\n",
    "\n",
    "    elif args.mode == 2 and not args.predict:\n",
    "        if os.path.exists(os.path.join(args.model_directory, 'model_supervised_stage.bin')):\n",
    "            response = input(f\"Supervised Fine Tuning Stage: Output directory ({os.path.join(args.model_directory, 'model_supervised_stage.bin')}) already exists and is not empty. Do you want to overwrite? (Y/N): \")\n",
    "            if response.lower() in ['yes', 'y']:\n",
    "                print('Only the Stage_2 (Supervised fine-tuning) will be performed')\n",
    "            else:\n",
    "                print('Model already fine-tuned.')\n",
    "                sys.exit()\n",
    "                \n",
    "    elif args.mode not in [0, 1, 2]:\n",
    "        print('The training mode specified incorrectly. Refer to the \"mode\" argument.')\n",
    "        sys.exit()\n",
    "\n",
    "    if args.mode in [0, 1] and args.contrastive_train:\n",
    "        #Configure logger \n",
    "        logger = logging.getLogger(__name__)\n",
    "        #Configure logging \n",
    "        FORMAT = '%(asctime)s - %(levelname)s -  %(module)s - %(funcName)s - %(message)s'\n",
    "        DATEFORMAT = '%d/%m/%Y %H:%M:%S:'\n",
    "        logging.basicConfig(level= logging.INFO, format= FORMAT, datefmt= DATEFORMAT)\n",
    "        logging.info(f\"The training begins for mode {args.mode}, the local rank is {args.local_rank}, Device: {args.device}\")\n",
    "\n",
    "        #Set the training seed\n",
    "        # random.seed(21)\n",
    "        # np.random.seed(21)\n",
    "        # torch.manual_seed(21)\n",
    "        # if args.get('available_gpus') > 1:\n",
    "        #     torch.cuda.manual_seed_all(21)\n",
    "        set_seed(args)\n",
    "    \n",
    "        #Configuration for distributed learning\n",
    "        distributed_learning(args)\n",
    "\n",
    "        #Apply synchronization to all subprocesses unless they are master process [0] or non-distributed learning [-1]\n",
    "        #This ensures only a master process will load the model\n",
    "        if args.local_rank not in [-1, 0]:\n",
    "            dist.barrier()\n",
    "\n",
    "        #Initialize the base model for training\n",
    "        if 'uncased' in args.model_version and not args.lowercase:\n",
    "            #print('The uncased base model is used and sequences are Cased, training cannot continue')\n",
    "            logger.warning(f\"The uncased base model is used and sequences are Cased, training cannot continue, consider changing 'lowercase' or 'model_version' parameter.\")\n",
    "            sys.exit()\n",
    "        config_class, base_model_class, tokenizer_class = Model_Classes[args.model_type]\n",
    "        config = config_class.from_pretrained(args.model_version)\n",
    "        base_model = base_model_class.from_pretrained(args.model_version, config= config).to(args.device)\n",
    "        if args.model_type.lower() in ['roberta', 'joberta']:\n",
    "            tokenizer = tokenizer_class.from_pretrained(args.model_version, add_prefix_space=True, use_fast = True)\n",
    "        else: \n",
    "            tokenizer = tokenizer_class.from_pretrained(args.model_version, do_lower_case= args.lowercase)\n",
    "            \n",
    "        model_contrast = Contrastskill(args, config, base_model)\n",
    "\n",
    "        #The continuation of the synchronization, sub-processes are halted until the master process loads the model,.\n",
    "        if args.local_rank == 0:\n",
    "            dist.barrier()\n",
    "\n",
    "        model_contrast.to(args.device)\n",
    "\n",
    "        #In case of the distributed training load the model as data DistributedDataParallel torch class\n",
    "        if args.available_gpus > 1:\n",
    "            model_contrast = DDP(model_contrast)\n",
    "\n",
    "        #Load the dataloader\n",
    "        dataloader = skill_dataloader(args, tokenizer, model_contrast)\n",
    "\n",
    "        #When training data was not prepared before\n",
    "        if args.prepare_data:\n",
    "            \n",
    "            print('Pairs are being formed for training...')\n",
    "            pre_data_path = os.path.join(args.data_directory, '/Pre-training')\n",
    "            with open(pre_data_path + '/selected_positives.json', 'r') as f:\n",
    "                positives = json.load(f)\n",
    "            with open(pre_data_path + '/selected_negatives.json', 'r') as f:\n",
    "                negatives = json.load(f)\n",
    "            training_dataset = dataloader.pair_data(positive_examples= positives, negative_examples= negatives)\n",
    "\n",
    "        elif not args.prepare_data:\n",
    "            prepared_data_path = os.path.join(args.data_directory, '/Prepared')\n",
    "            print('Training Data ready...')\n",
    "            with open(prepared_data_path + '/training_dataset.json', 'r') as f:\n",
    "                training_dataset = json.load(f)\n",
    "\n",
    "        train_contrast(args, model= model_contrast, training_data= training_dataset)\n",
    "    \n",
    "    if args.mode in [1, 2] and args.supervised_train:\n",
    "        #Configure logger\n",
    "        logger = logging.getLogger(__name__)\n",
    "        #Configure logging \n",
    "        FORMAT = '%(asctime)s - %(levelname)s -  %(module)s - %(funcName)s - %(message)s'\n",
    "        DATEFORMAT = '%d/%m/%Y %H:%M:%S:'\n",
    "        logging.basicConfig(level= logging.INFO, format= FORMAT, datefmt= DATEFORMAT)\n",
    "        logging.info(f\"The training begins for mode {args.mode}, the local rank is {args.local_rank}, Device: {args.device}\")\n",
    "        \n",
    "        set_seed(args)\n",
    "        distributed_learning(args)\n",
    "        \n",
    "        if args.local_rank not in [-1, 0]:\n",
    "            dist.barrier()\n",
    "\n",
    "        #Initialize the model for training \n",
    "        if 'uncased' in args.model_version and not args.lowercase:\n",
    "            #print('The uncased base model is used and sequences are Cased, training cannot continue')\n",
    "            logger.warning(f\"The uncased base model is used and sequences are Cased, training cannot continue, consider changing 'lowercase' or 'model_version' parameter.\")\n",
    "            sys.exit()\n",
    "            \n",
    "        config_class, base_model_class, tokenizer_class = Model_Classes[args.model_type]\n",
    "        config = config_class.from_pretrained(args.model_version)\n",
    "        base_model = base_model_class.from_pretrained(args.model_version, config= config).to(args.device)\n",
    "        if args.model_type.lower() in ['roberta', 'joberta']:\n",
    "            tokenizer = tokenizer_class.from_pretrained(args.model_version, add_prefix_space=True, use_fast = True)\n",
    "        else: \n",
    "            tokenizer = tokenizer_class.from_pretrained(args.model_version, do_lower_case= args.lowercase)\n",
    "\n",
    "            \n",
    "        if not args.supervised_raw:\n",
    "            print('The pre-trained model from contrastive_stage is used for supervised training')\n",
    "            #Load the pre-trained model\n",
    "            state_dict = torch.load(f\"{args.model_directory}/model_contrastive_stage.bin\")\n",
    "            #Replace the layer names to match that of the base_encoder\n",
    "            updated_state_dict = {k.replace('base_encoder.', ''): v for k, v in state_dict.items() if k.startswith('base_encoder.')}\n",
    "            #Update the weights of the base model\n",
    "            base_model.load_state_dict(updated_state_dict, strict=False)\n",
    "            #Configure the supervised model\n",
    "            supervised_model = BioTaggingModel(args, model= base_model, num_labels = args.supervised_num_labels)\n",
    "        else:\n",
    "            print('The base fine-tuned model is used for supervised training')\n",
    "            supervised_model = BioTaggingModel(args, model= base_model, num_labels = args.supervised_num_labels)\n",
    "            \n",
    "        if args.local_rank == 0:\n",
    "            dist.barrier()\n",
    "            \n",
    "        supervised_model.to(args.device)\n",
    "        \n",
    "        if args.available_gpus > 1:\n",
    "            supervised_model = DDP(supervised_model)\n",
    "            \n",
    "        #prepare the training data. In this case there is no need for a designated dataloader since tensorize_data function handles all pre-processing\n",
    "        supervised_training_data = []\n",
    "        dev_data = []\n",
    "        sup_data_path = os.path.join(args.data_directory, '/Supervised', args.supervised_dataset)\n",
    "        with open(sup_data_path+'/train.json', 'r') as f:\n",
    "            for line in f:\n",
    "                supervised_training_data.append(json.loads(line.strip()))\n",
    "        with open(sup_data_path+'/dev.json', 'r') as f:\n",
    "            for line in f:\n",
    "                dev_data.append(json.loads(line.strip()))\n",
    "    \n",
    "        supervised_training_dataset = tensorize_data(args, supervised_training_data, tokenizer)\n",
    "\n",
    "        if args.supervised_train:\n",
    "            if not dev_data:\n",
    "                train_supervised(args, supervised_training_dataset, supervised_model)\n",
    "            else:\n",
    "                train_supervised(args, supervised_training_dataset, supervised_model, tokenizer, dev_data)\n",
    "            \n",
    "        \n",
    "    if args.get('predict'):\n",
    "        set_seed(args)\n",
    "        print('Loading the fine tuned model for prediction')\n",
    "        config_class, base_model_class, tokenizer_class = Model_Classes[args.model_type]\n",
    "        config = config_class.from_pretrained(args.model_version)\n",
    "        base_model = base_model_class.from_pretrained(args.model_version, config= config).to(args.device)\n",
    "        if args.model_type.lower() in ['roberta', 'joberta']:\n",
    "            tokenizer = tokenizer_class.from_pretrained(args.model_version, add_prefix_space=True, use_fast = True)\n",
    "        else: \n",
    "            tokenizer = tokenizer_class.from_pretrained(args.model_version, do_lower_case= args.lowercase)\n",
    "        #Initialize the BIO model\n",
    "        supervised_model = BioTaggingModel(args, model= base_model, num_labels = args.get('supervised_num_labels'))\n",
    "        try:\n",
    "            supervised_model.load_state_dict(torch.load(f\"{args.model_directory}/model_supervised_stage.bin\"))\n",
    "            supervised_model.to(args.device)\n",
    "            print('model weights loaded')\n",
    "        except AttributeError:\n",
    "            supervised_model = torch.nn.DataParallel(supervised_model) \n",
    "            supervised_model.load_state_dict(torch.load(f\"{args.model_directory}/model_supervised_stage.bin\"))\n",
    "            supervised_model = supervised_model.module\n",
    "            if args.available_gpus > 1 and args.local_rank != -1:\n",
    "                supervised_model = DDP(supervised_model)\n",
    "            supervised_model.to(args.device)\n",
    "        #Load the test data\n",
    "        supervised_test_data = []\n",
    "        file_path = os.path.join(args.data_directory, '/Supervised', args.supervised_dataset, 'test.json')\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                supervised_test_data.append(json.loads(line.strip()))\n",
    "        #Predict and Evaluate \n",
    "        evaluation(args, supervised_test_data, supervised_model, tokenizer, final=True)\n",
    "        torch.cuda.empty_cache()\n",
    "        print('All models trained, see evaluation above')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Parse parameters\n",
    "    args = parse_args()\n",
    "    \n",
    "    #Run the model\n",
    "    model_deploy(args)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
